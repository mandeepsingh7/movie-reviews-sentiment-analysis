{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter, OrderedDict\n",
    "from torchtext.vocab import vocab\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "from zipfile import ZipFile \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "#!unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 25000\n",
    "THRESHOLD_FREQ = 5\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Imagine The Big Chill with a cast of twenty-so...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'd have to say that I've seen worse Sci Fi Ch...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Director Fabio Barreto got a strange Academy N...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pretty bad PRC cheapie which I rarely bother t...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a very intriguing short movie by David...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating  Sentiment\n",
       "0  Imagine The Big Chill with a cast of twenty-so...       2          0\n",
       "1  I'd have to say that I've seen worse Sci Fi Ch...       3          0\n",
       "2  Director Fabio Barreto got a strange Academy N...       1          0\n",
       "3  Pretty bad PRC cheapie which I rarely bother t...       4          0\n",
       "4  This is a very intriguing short movie by David...       8          1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/imdb_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Review'].values \n",
    "y = df['Sentiment'].values \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    # Replacing n't with not since it could be really important in sentiment analysis\n",
    "    text = re.sub(\"n't\", ' not ', text)\n",
    "    # Removing URLs\n",
    "    text = re.sub('(http).*\\/', ' ', text)\n",
    "    # Removing HTML tags\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    # Extracting emoticons\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|P|D|]|})', text)\n",
    "    # Removing punctuations\n",
    "    text = re.sub('[\\W]+', ' ', text.lower())\n",
    "    # Adding emoticons at end and converting :-) to :)\n",
    "    text = text + ' ' + ' '.join(emoticons).replace('-', '')\n",
    "    \n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size = 85908\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_counter = Counter()\n",
    "lengths = []\n",
    "for review in X_train:\n",
    "    tokens = tokenizer(review)\n",
    "    lengths.append(len(tokens))\n",
    "    token_counter.update(tokens)\n",
    "print(f'Vocabulary size = {len(token_counter)}')\n",
    "sns.histplot(lengths)\n",
    "plt.xlabel('Sentence Lengths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:    \n",
    "    def __init__(self):\n",
    "        self.vocabulary = None \n",
    "        \n",
    "    def build_vocabulary(self, sentences):\n",
    "        token_counter = Counter()\n",
    "        for sentence in sentences:\n",
    "            token_counter.update(tokenizer(sentence))\n",
    "        sorted_by_freq_tuples = sorted(token_counter.items(), key=lambda x: x[1], reverse=True)[:VOCAB_SIZE]\n",
    "        ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "        specials = ['<PAD>', '<UNK>']\n",
    "        self.vocabulary = vocab(ordered_dict, specials=specials, min_freq=THRESHOLD_FREQ)\n",
    "        self.vocabulary.set_default_index(self.vocabulary['<UNK>'])\n",
    "    \n",
    "    def numericalize(self, sentence):\n",
    "        tokenized_sentence = tokenizer(sentence)\n",
    "        return [self.vocabulary[token] if token in self.vocabulary else self.vocabulary['<UNK>'] for token in tokenized_sentence] \n",
    "    \n",
    "    def denumericalize(self, list):\n",
    "        return [self.vocabulary.get_itos()[idx] if idx < len(self.vocabulary) else '<UNK>' for idx in list ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = Vocabulary()\n",
    "v1.build_vocabulary(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Glove Embeddings (creating weight matrix for nn.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dictionary = dict()\n",
    "with open(r'C:\\Users\\mndpp\\Desktop\\Github_Projects\\\\01_movie_review_sentiment\\glove.6B.100d.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.split(' ')\n",
    "        #print(line)\n",
    "        glove_dictionary[line[0]] = np.array(line[1:], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(v1.vocabulary)\n",
    "weight_matrix = np.zeros((vocab_size, 100))\n",
    "for word, idx in v1.vocabulary.get_stoi().items():\n",
    "    if word == '<PAD>':\n",
    "        continue\n",
    "    if word in glove_dictionary:\n",
    "        weight_matrix[idx] = glove_dictionary[word]\n",
    "    else:\n",
    "        weight_matrix[idx] = np.random.normal(size=(100,))\n",
    "weight_matrix = torch.tensor(weight_matrix).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, reviews_list, sentiment_list, vocabulary):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.reviews = reviews_list \n",
    "        self.targets = sentiment_list \n",
    "        self.v1 = vocabulary\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        review = self.reviews[index]\n",
    "        target = self.targets[index]\n",
    "        \n",
    "        numericalized_review = torch.tensor(self.v1.numericalize(review))\n",
    "        \n",
    "        return numericalized_review, torch.tensor(target).unsqueeze(0).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Collate:\n",
    "    def __init__(self, pad_idx) :\n",
    "        self.pad_idx = pad_idx \n",
    "    \n",
    "    def __call__(self, batch) :\n",
    "        reviews = [item[0] for item in batch]\n",
    "        reviews = pad_sequence(reviews, batch_first=True, padding_value=self.pad_idx)\n",
    "        targets = torch.cat([item[1].unsqueeze(0) for item in batch], dim=0)\n",
    "        return reviews, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(reviews_list, sentiment_list, vocabulary, batch_size, shuffle=True):\n",
    "    dataset = CustomDataset(reviews_list, sentiment_list, vocabulary)\n",
    "    pad_idx = dataset.v1.vocabulary['<PAD>']\n",
    "    dataloader = DataLoader(\n",
    "        dataset = dataset,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = shuffle,\n",
    "        collate_fn = Collate(pad_idx=pad_idx)\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = Vocabulary()\n",
    "v1.build_vocabulary(X_train)\n",
    "train_loader = get_dataloader(X_train, y_train, v1, BATCH_SIZE)\n",
    "valid_loader = get_dataloader(X_valid, y_valid, v1, BATCH_SIZE)\n",
    "test_loader = get_dataloader(X_test, y_test, v1, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer, filename = 'checkpoint.pth.tar'):\n",
    "    checkpoint = torch.load(filename)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    max_accuracy = checkpoint['max_acc']\n",
    "    best_model = checkpoint['best_model']\n",
    "    return model, optimizer, max_accuracy, best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, data_loader, loss_fn):\n",
    "    total_correct = 0.0\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for _, batch in enumerate(data_loader):\n",
    "            inputs = batch[0].to(device)\n",
    "            labels = batch[1].to(device)\n",
    "            y_preds = model(inputs)\n",
    "            loss = loss_fn(y_preds, labels)\n",
    "            total_loss += loss.item()*len(inputs)\n",
    "            correct_counts = (torch.where(y_preds>0.5, 1, 0) == labels).float().sum().item()\n",
    "            total_correct += correct_counts\n",
    "    accuracy = total_correct/len(data_loader.dataset)*100\n",
    "    avg_loss = total_loss/len(data_loader.dataset)  \n",
    "    return accuracy, avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, model_name, optimizer, scheduler, loss_fn, train_data_loader, valid_data_loader, load_model=False, save_model=True, num_epochs = 10, patience=5):\n",
    "    history = []\n",
    "    max_accuracy = 0.0\n",
    "    best_model = None\n",
    "    if load_model:\n",
    "        model, optimizer, max_accuracy, best_model = load_checkpoint(model, optimizer, checkpoint, model_name + model_name + '_checkpoint.pth.tar')\n",
    "    count = 0\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        for batch_idx, batch in enumerate(train_data_loader):\n",
    "            inputs = batch[0].to(device)\n",
    "            labels = batch[1].to(device)\n",
    "            y_preds = model(inputs)\n",
    "            loss = loss_fn(y_preds, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 100 == 0 :\n",
    "                print(f'Epoch No. {epoch+1}/{num_epochs} | Batch No. {batch_idx}/{len(train_data_loader)} | Loss = {loss:.5f}')\n",
    "        training_accuracy, training_loss = get_accuracy(model, train_data_loader, loss_fn)\n",
    "        valid_accuracy, valid_loss = get_accuracy(model, valid_data_loader, loss_fn)\n",
    "        print(f'Training Accuracy = {training_accuracy:.2f}% | Loss = {training_loss:.4f}')\n",
    "        print(f'Valid Accuracy = {valid_accuracy:.2f}% | Loss = {valid_loss:.4f}')\n",
    "        history.append([training_accuracy, training_loss, valid_accuracy, valid_loss])\n",
    "        scheduler.step(valid_loss)\n",
    "        if valid_accuracy > max_accuracy :\n",
    "            count = 0\n",
    "            max_accuracy = valid_accuracy\n",
    "            checkpoint = {\n",
    "                'model'      : model.state_dict(),\n",
    "                'optimizer'  : optimizer.state_dict(),\n",
    "                'best_model' : model.state_dict(),\n",
    "                'max_acc'    : valid_accuracy\n",
    "            }\n",
    "            best_model = model.state_dict()\n",
    "            if save_model:\n",
    "                save_checkpoint(checkpoint, model_name + '_checkpoint.pth.tar')\n",
    "        else :\n",
    "            count += 1\n",
    "            checkpoint = {\n",
    "                'model'      : model.state_dict(),\n",
    "                'optimizer'  : optimizer.state_dict(),\n",
    "                'best_model' : best_model,\n",
    "                'max_acc'    : max_accuracy\n",
    "            }\n",
    "            if save_model:\n",
    "                save_checkpoint(checkpoint, model_name + '_checkpoint.pth.tar')\n",
    "            if (count >= patience):\n",
    "                print(f'Early stop at Epoch Number {epoch + 1}')\n",
    "                break \n",
    "    return model, history    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_training(trained_model, loss_fn, test_loader, history, model_name):\n",
    "    test_loss, test_acc = get_accuracy(trained_model, test_loader, loss_fn)\n",
    "    history_np = np.array(history)\n",
    "    fig, axes = plt.subplots(1, 2, figsize = (12, 4))\n",
    "    epochs_list = np.arange(1, len(history_np)+1)\n",
    "    axes[0].plot(epochs_list, history_np[:, 0], label = \"Training Accuracy\", marker = '.')\n",
    "    axes[0].plot(epochs_list, history_np[:, 2], label = \"Validation Accuracy\", marker = '.')\n",
    "    axes[0].set_xlabel('Epochs')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].plot(epochs_list, history_np[:, 1], label = \"Training Loss\", marker = '.')\n",
    "    axes[1].plot(epochs_list, history_np[:, 3], label = \"Validation Loss\", marker = '.')\n",
    "    axes[1].set_xlabel('Epochs')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].legend()\n",
    "\n",
    "    fig.suptitle(f'Training for {model_name}')\n",
    "    plt.show()\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, n_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=v1.vocabulary['<PAD>'])\n",
    "        self.embedding.load_state_dict({'weight': weight_matrix})\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=n_layers, batch_first=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:,-1,:]\n",
    "        out = self.fc(out)\n",
    "        return out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (embedding): Embedding(25002, 100, padding_idx=0)\n",
      "  (lstm): LSTM(100, 256, batch_first=True)\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (4): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LSTM(vocab_size=len(v1.vocabulary), embed_size = 100, hidden_size = 256, n_layers = 1)\n",
    "learning_rate = 0.002\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "num_epochs = 10\n",
    "patience = 5\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No. 1/100 | Batch No. 0/1000 | Loss = 0.69574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trained_model , history_model \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLSTM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 10\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(model, model_name, optimizer, scheduler, loss_fn, train_data_loader, valid_data_loader, load_model, save_model, num_epochs, patience)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_epochs)):\n\u001b[0;32m      9\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_data_loader):\n\u001b[0;32m     11\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     12\u001b[0m         labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\mndpp\\Desktop\\Github_Projects\\01_movie_review_sentiment\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\mndpp\\Desktop\\Github_Projects\\01_movie_review_sentiment\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\mndpp\\Desktop\\Github_Projects\\01_movie_review_sentiment\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\mndpp\\Desktop\\Github_Projects\\01_movie_review_sentiment\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[15], line 17\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     13\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index]\n\u001b[0;32m     15\u001b[0m numericalized_review \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mnumericalize(review))\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m numericalized_review, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_model , history_model = training(model, 'LSTM', optimizer, scheduler, loss_fn, train_loader, valid_loader, load_model=False, save_model=True, num_epochs = 100, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = post_training(trained_model, loss_fn, test_loader, history_model, 'LSTM')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
