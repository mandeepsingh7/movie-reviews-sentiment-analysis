{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import transformers\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown 1ZDFmDZDOi_hrfXrKYHjt9RorHBEcT1mq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Path(os.path.join(os.getcwd(),'imdb_data.csv')))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    # Replacing n't with not since it could be really important in sentiment analysis\n",
    "    text = re.sub(\"n't\", ' not ', text)\n",
    "    # Removing URLs\n",
    "    text = re.sub('(http).*\\/', ' ', text)\n",
    "    # Removing HTML tags\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    # Extracting emoticons\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|P|D|]|})', text)\n",
    "    # Removing punctuations\n",
    "    text = re.sub('[\\W]+', ' ', text.lower())\n",
    "    # Adding emoticons at end and converting :-) to :)\n",
    "    text = text + ' ' + ' '.join(emoticons).replace('-', '')\n",
    "    return text   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review'] = df['Review'].apply(text_preprocessing)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into Train, Test, Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Review'].values \n",
    "y = df['Sentiment'].values \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42, stratify=y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained( 'distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = tokenizer(list(X_train), truncation=True, padding=True)\n",
    "valid_tokenized = tokenizer(list(X_valid), truncation=True, padding=True)\n",
    "test_tokenized = tokenizer(list(X_test), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, tokenized, labels):\n",
    "        self.tokenized = tokenized\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = {key: torch.tensor(value[index]) for key, value in self.tokenized.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[index])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomDataset(train_tokenized, y_train)\n",
    "train_loader = DataLoader(train_data, BATCH_SIZE, shuffle=True)\n",
    "\n",
    "valid_data = CustomDataset(valid_tokenized, y_valid)\n",
    "valid_loader = DataLoader(valid_data, BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_data = CustomDataset(test_tokenized, y_test)\n",
    "test_loader = DataLoader(test_data, BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, data_loader):\n",
    "    accuracy = 0.0\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for _, batch in enumerate(data_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask = attention_mask, labels = labels)\n",
    "            loss = outputs['loss']\n",
    "            total_loss += loss.item()*len(labels)\n",
    "            logits = outputs['logits']\n",
    "            y_preds = torch.argmax(logits, 1)\n",
    "            correct_counts = (y_preds == labels).float().sum().item()\n",
    "            accuracy += correct_counts \n",
    "    accuracy = accuracy/len(data_loader.dataset)\n",
    "    total_loss = total_loss/len(data_loader.dataset)  \n",
    "    return accuracy, total_loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, model_name, optimizer, train_data_loader, valid_data_loader, num_epochs = 10):\n",
    "    history = []\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        for batch_idx, batch in enumerate(train_data_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask = attention_mask, labels = labels)\n",
    "            \n",
    "            loss = outputs['loss']\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch_idx % 200 == 0 :\n",
    "                print(f'Epoch No. {epoch+1}/{num_epochs} | Batch No. {batch_idx}/{len(train_data_loader)} | Loss = {loss:.5f}')\n",
    "        training_accuracy, training_loss = get_accuracy(model, train_data_loader)\n",
    "        valid_accuracy, valid_loss = get_accuracy(model, valid_data_loader)\n",
    "        print(f'Training Accuracy = {training_accuracy:.2f}%, Loss = {training_loss:.4f}')\n",
    "        print(f'Valid Accuracy = {valid_accuracy:.2f}%, Loss = {valid_loss:.4f}')\n",
    "        history.append([training_accuracy, training_loss, valid_accuracy, valid_loss])\n",
    "    return model, history    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_training(trained_model, test_loader, history, model_name):\n",
    "    test_acc, test_loss = get_accuracy(trained_model, test_loader)\n",
    "    history_np = np.array(history)\n",
    "    fig, axes = plt.subplots(1, 2, figsize = (12, 4))\n",
    "    epochs_list = np.arange(1, len(history_np)+1)\n",
    "    axes[0].plot(epochs_list, history_np[:, 0], label = \"Training Accuracy\", marker = '.')\n",
    "    axes[0].plot(epochs_list, history_np[:, 2], label = \"Validation Accuracy\", marker = '.')\n",
    "    axes[0].set_xlabel('Epochs')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].plot(epochs_list, history_np[:, 1], label = \"Training Loss\", marker = '.')\n",
    "    axes[1].plot(epochs_list, history_np[:, 3], label = \"Validation Loss\", marker = '.')\n",
    "    axes[1].set_xlabel('Epochs')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].legend()\n",
    "\n",
    "    fig.suptitle(f'Training for {model_name}')\n",
    "    plt.show()\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training using DistilBert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "trained_model, history = training(model, 'DistilBERT', optimizer, train_loader, valid_loader, num_epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = post_training(trained_model, test_loader, history, 'DistilBERT')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
